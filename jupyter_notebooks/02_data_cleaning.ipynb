{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5694508",
   "metadata": {},
   "source": [
    "# 02 - Data Cleaning\n",
    "\n",
    "## Objective\n",
    "Load the latest raw snapshots for each ticker, clean and standardise the structure, then save a single tidy dataset for analysis and modelling.\n",
    "\n",
    "## Inputs\n",
    "- Raw CSV snapshots in `data/raw/<version>/`\n",
    "- Version label (e.g. v1)\n",
    "\n",
    "## Outputs\n",
    "- Cleaned dataset saved to `data/processed/<version>/clean_prices_<version>_<timestamp>.csv`\n",
    "- Basic data quality checks (shape, missing values)\n",
    "\n",
    "## CRISP-DM Stage\n",
    "Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7d9c40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the project root importable (so `import src...` works in notebooks)\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(\"..\").resolve()  # notebooks live in jupyter_notebooks/\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(\"Project root added to sys.path:\", PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "021a25fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from src.config import DEFAULT_TICKERS, DEFAULT_VERSION, get_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fefbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = DEFAULT_VERSION\n",
    "TICKERS = DEFAULT_TICKERS\n",
    "\n",
    "paths = get_paths(VERSION)\n",
    "RAW_DIR = paths.raw_dir\n",
    "PROCESSED_DIR = paths.processed_dir\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Raw dir:\", RAW_DIR)\n",
    "print(\"Processed dir:\", PROCESSED_DIR)\n",
    "print(\"Tickers:\", \", \".join(TICKERS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7f4eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "\n",
    "def latest_snapshot_for_ticker(raw_dir: Path, ticker: str, version: str) -> Path:\n",
    "    pattern = f\"{ticker}_raw_{version}_*.csv\"\n",
    "    matches = sorted(raw_dir.glob(pattern))\n",
    "    if not matches:\n",
    "        raise FileNotFoundError(f\"No raw snapshots found for {ticker} in {raw_dir}\")\n",
    "    return matches[-1]\n",
    "\n",
    "\n",
    "files: Dict[str, Path] = {\n",
    "    t: latest_snapshot_for_ticker(RAW_DIR, t, VERSION) for t in TICKERS\n",
    "}\n",
    "\n",
    "for t, f in files.items():\n",
    "    print(t, \"->\", f.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8cd1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUIRED_COLUMNS = [\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj_Close\", \"Volume\", \"Ticker\"]\n",
    "\n",
    "\n",
    "def clean_prices(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # Standardise column names\n",
    "    df.columns = [str(c).strip().replace(\" \", \"_\") for c in df.columns]\n",
    "\n",
    "    # Required columns checks\n",
    "    if \"Ticker\" not in df.columns:\n",
    "        raise KeyError(\"Expected 'Ticker' column is missing.\")\n",
    "    if \"Date\" not in df.columns:\n",
    "        raise KeyError(\"Expected 'Date' column is missing.\")\n",
    "\n",
    "    # Ensure Adj_Close exists (fallback to Close)\n",
    "    if \"Adj_Close\" not in df.columns and \"Close\" in df.columns:\n",
    "        df[\"Adj_Close\"] = df[\"Close\"]\n",
    "\n",
    "    # Parse dates\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"Date\"])\n",
    "\n",
    "    # Coerce numerics\n",
    "    for col in [\"Open\", \"High\", \"Low\", \"Close\", \"Adj_Close\", \"Volume\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # Drop duplicates + sort\n",
    "    df = df.drop_duplicates(subset=[\"Ticker\", \"Date\"])\n",
    "    df = df.sort_values([\"Ticker\", \"Date\"])\n",
    "\n",
    "    # Ensure the output schema is consistent (prevents future concat bugs)\n",
    "    for col in REQUIRED_COLUMNS:\n",
    "        if col not in df.columns:\n",
    "            df[col] = pd.NA\n",
    "\n",
    "    df = df[REQUIRED_COLUMNS]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ad232b",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "\n",
    "for ticker, path in files.items():\n",
    "    temp = pd.read_csv(path)\n",
    "    temp = clean_prices(temp)\n",
    "    frames.append(temp)\n",
    "\n",
    "clean_df = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "# Quick preview (3 rows per ticker so it never looks like NaNs)\n",
    "display(clean_df.groupby(\"Ticker\").head(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
